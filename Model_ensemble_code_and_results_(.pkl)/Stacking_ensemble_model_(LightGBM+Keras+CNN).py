# -*- coding: utf-8 -*-
"""Stacking_Ensemble_Model_(LightGBM+Keras+CNN)

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/14wcanVBBTYXA5eYxh6kZ_HxK6HZdpqcz
"""

from google.colab import drive
drive.mount('/content/drive')

pip install scikit-optimize lightgbm optuna bayesian-optimization

pip install scikeras

import joblib
import pandas
import optuna
import lightgbm


from lightgbm import LGBMClassifier
from skopt import BayesSearchCV
from skopt.space import Integer, Categorical
from sklearn.pipeline import Pipeline
from sklearn.preprocessing import StandardScaler
from sklearn.metrics import classification_report, accuracy_score, f1_score
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score


import numpy
import tensorflow


from tensorflow.keras import layers
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.models import Sequential
from keras.callbacks import EarlyStopping, ReduceLROnPlateau
from tensorflow.keras.layers import Dense, Dropout, Conv1D, Conv2D, MaxPooling1D, MaxPooling2D, Flatten, BatchNormalization
# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier
from scikeras.wrappers import KerasClassifier, KerasRegressor


from sklearn.ensemble import StackingClassifier
from sklearn.linear_model import LogisticRegression


import matplotlib.pyplot as plot

datafile = pandas.read_csv('/content/drive/MyDrive/Colab Notebooks/WhiteHat_School_Akpago/BigDataCenter_CSV_File/Dataset_Final4.csv')

datafile.head()

entropy= list(filter(lambda x: ('Entropy' in x),datafile.columns))
ATT_Technique_col = list(filter(lambda x: ('ATT_Tech_pca' in x),datafile.columns))
ATT_Tactic_col = list(filter(lambda x: ('ATT_Tactic_pca' in x),datafile.columns))
MBC_Object_col = list(filter(lambda x: ('MBC_obj_pca' in x),datafile.columns))
MBC_Behavior_col = list(filter(lambda x: ('MBC_behave_pca' in x),datafile.columns))
namespace_col = list(filter(lambda x: ('namespace_' in x),datafile.columns))
capabilityNum= list(filter(lambda x: ('capability_pca' in x),datafile.columns))


print(entropy)
print(ATT_Technique_col)
print(ATT_Tactic_col)
print(MBC_Object_col)
print(MBC_Behavior_col)
print(namespace_col)
print(capabilityNum)

target_datafile = datafile['Y']


selected_columns = [
    datafile[entropy],
    datafile[ATT_Technique_col],
    datafile[ATT_Tactic_col],
    datafile[MBC_Object_col],
    datafile[MBC_Behavior_col],
    datafile[namespace_col],
    datafile[capabilityNum]
]
feature_datafile = pandas.concat(selected_columns, axis=1)


x_train, x_test, y_train, y_test = train_test_split(feature_datafile, target_datafile, test_size=0.3, random_state=42)

##### LightGBM #####

def objective(trial):
    param = {
        'objective': 'binary',
        'metric': 'binary_logloss',
        'verbosity': -1,
        'boosting_type': 'gbdt',
        'num_leaves': trial.suggest_int('num_leaves', 20, 150),
        'learning_rate': trial.suggest_float('learning_rate', 1e-8, 1e-1, log=True),
        'n_estimators': trial.suggest_int('n_estimators', 50, 1000),
        'max_depth': trial.suggest_int('max_depth', 3, 15),
        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),
        'subsample': trial.suggest_float('subsample', 0.4, 1.0),
        'colsample_bytree': trial.suggest_float('colsample_bytree', 0.4, 1.0),
    }

    lightgbm_base = lightgbm.LGBMClassifier(**param, random_state=42)
    lightgbm_base.fit(x_train, y_train)
    preds = lightgbm_base.predict(x_test)
    accuracy = accuracy_score(y_test, preds)

    return accuracy


study = optuna.create_study(direction='maximize')
study.optimize(objective, n_trials=100)


best_params = study.best_params
print(best_params)


lightgbm_model = lightgbm.LGBMClassifier(**best_params, random_state=42)


lightgbm_model.fit(x_train, y_train)


preds = lightgbm_model.predict(x_test)
accuracy = accuracy_score(y_test, preds)
print(f"LightGBM Validation Accuracy: {accuracy}")

##### Keras #####

def create_keras_model(input_dim):
    model = Sequential([
        Dense(512, input_dim=input_dim, activation='relu'),
        BatchNormalization(),
        Dropout(0.3),

        Dense(256, activation='relu'),
        BatchNormalization(),
        Dropout(0.3),

        Dense(128, activation='relu'),
        BatchNormalization(),
        Dropout(0.3),

        Dense(64, activation='relu'),
        BatchNormalization(),
        Dropout(0.3),

        Dense(1, activation='sigmoid')
    ])
    model.compile(optimizer=Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=['accuracy'])
    return model


input_dimension = x_train.shape[1]


keras_model = KerasClassifier(build_fn=lambda: create_keras_model(input_dimension), epochs=50, batch_size=12, verbose=0)


early_stopping = EarlyStopping(patience=10, restore_best_weights=True)
reduce_learning_rate = ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6)


history_keras = keras_model.fit(x_train, y_train, validation_data=(x_test, y_test), callbacks=[early_stopping, reduce_learning_rate])


# plot.figure(figsize=(12, 4))


# plot.subplot(1, 2, 1)
# plot.plot(history.history['accuracy'], label='Train Accuracy')
# plot.plot(history.history['val_accuracy'], label='Validation Accuracy')
# plot.xlabel('Epoch')
# plot.ylabel('Accuracy')
# plot.legend()


# plot.subplot(1, 2, 2)
# plot.plot(history.history['loss'], label='Train Loss')
# plot.plot(history.history['val_loss'], label='Validation Loss')
# plot.xlabel('Epoch')
# plot.ylabel('Loss')
# plot.legend()


# plot.tight_layout()
# plot.show()


y_pred_valid = keras_model.predict(x_test)


accuracy = accuracy_score(y_test, y_pred_valid)
print(f"Keras Validation Accuracy: {accuracy}") # 0.8877526259229729

##### CNN #####

def create_cnn_model():
    model = Sequential()
    model.add(Conv1D(32, 3, activation='relu', input_shape=(x_train.shape[1], 1)))
    model.add(MaxPooling1D(2))
    model.add(Dropout(0.3))

    model.add(Conv1D(64, 3, activation='relu'))
    model.add(MaxPooling1D(2))
    model.add(Dropout(0.3))

    model.add(Flatten())
    model.add(Dense(64, activation='relu'))
    model.add(Dropout(0.3))

    model.add(Dense(1, activation='sigmoid'))

    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    return model


cnn_model = KerasClassifier(build_fn=create_cnn_model, epochs=50, batch_size=32, verbose=0)


early_stopping = EarlyStopping(patience=10, restore_best_weights=True)
reduce_learning_rate = ReduceLROnPlateau(factor=0.5, patience=5, min_lr=1e-6)


history_cnn = cnn_model.fit(x_train.values[..., numpy.newaxis], y_train, validation_data=(x_test.values[..., numpy.newaxis], y_test), epochs=50, batch_size=32, callbacks=[early_stopping, reduce_learning_rate], verbose=0)


# plot.figure(figsize=(12, 4))


# plot.subplot(1, 2, 1)
# plot.plot(history_cnn.history['accuracy'], label='Train Accuracy')
# plot.plot(history_cnn.history['val_accuracy'], label='Validation Accuracy')
# plot.xlabel('Epoch')
# plot.ylabel('Accuracy')
# plot.legend()


# plot.subplot(1, 2, 2)
# plot.plot(history_cnn.history['loss'], label='Train Loss')
# plot.plot(history_cnn.history['val_loss'], label='Validation Loss')
# plot.xlabel('Epoch')
# plot.ylabel('Loss')
# plot.legend()


# plot.tight_layout()
# plot.show()


y_pred_valid = cnn_model.predict(x_test.values[..., numpy.newaxis])
y_pred_valid = numpy.where(y_pred_valid > 0.5, 1, 0)


accuracy = accuracy_score(y_test, y_pred_valid)
print(f"CNN Validation Accuracy: {accuracy}") # 0.8668145734391791

##### Stacking Ensemble (LightGBM + Keras) #####

estimators = [
    ('LightGBM', lightgbm_model),
    ('Keras', keras_model)
]

stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())


stacking_model.fit(x_train, y_train)

y_pred = stacking_model.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)


print(f'Stacking Ensemble Model Accuracy (LightGBM + Keras) : {accuracy}') # 0.9508441085728152

# joblib.dump(stacking_model, "/content/drive/MyDrive/Stacking_Ensemble_Model_(LightGBM_+_Keras).pkl")

##### Stacking Ensemble (LightGBM + CNN) #####

estimators = [
    ('LightGBM', lightgbm_model),
    ('CNN', cnn_model)
]

stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())


stacking_model.fit(x_train, y_train)

y_pred = stacking_model.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)


print(f'Stacking Ensemble Model Accuracy (LightGBM + CNN) : {accuracy}') # 9548787702226228

# joblib.dump(stacking_model, "/content/drive/MyDrive/Stacking_Ensemble_Model_(LightGBM_+_CNN)_().pkl")

##### Stacking Ensemble (LightGBM + Keras + CNN) #####

estimators = [
    ('LightGBM', lightgbm_model),
    ('Keras', keras_model),
    ('CNN', cnn_model)
]

stacking_model = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression())


stacking_model.fit(x_train, y_train)

y_pred = stacking_model.predict(x_test)
accuracy = accuracy_score(y_test, y_pred)


print(f'Stacking Ensemble Model Accuracy (LightGBM + Keras + CNN) : {accuracy}') # 9505667833743544

joblib.dump(stacking_model, "/content/drive/MyDrive/Stacking_Ensemble_Model_(LightGBM_+_Keras_+_CNN).pkl")